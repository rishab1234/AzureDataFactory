{
	"name": "dataflow1",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "sourceforagg",
						"type": "DatasetReference"
					},
					"name": "source1"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "prod_category_1",
						"type": "DatasetReference"
					},
					"name": "sink1"
				},
				{
					"dataset": {
						"referenceName": "prod_category_1",
						"type": "DatasetReference"
					},
					"name": "sink2"
				},
				{
					"dataset": {
						"referenceName": "prod_category_1",
						"type": "DatasetReference"
					},
					"name": "sink3"
				},
				{
					"dataset": {
						"referenceName": "prod_category_1",
						"type": "DatasetReference"
					},
					"name": "sink4"
				}
			],
			"transformations": [
				{
					"name": "filter1"
				},
				{
					"name": "filter2"
				},
				{
					"name": "filter3"
				},
				{
					"name": "filter4"
				}
			],
			"scriptLines": [
				"source(output(",
				"          ProductCategoryID as integer,",
				"          ParentProductCategoryID as integer,",
				"          Name as string,",
				"          rowguid as string,",
				"          ModifiedDate as timestamp",
				"     ),",
				"     allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     isolationLevel: 'READ_UNCOMMITTED',",
				"     format: 'table') ~> source1",
				"source1 filter(equals(ParentProductCategoryID, 1)) ~> filter1",
				"source1 filter(equals(ParentProductCategoryID, 2)) ~> filter2",
				"source1 filter(equals(ParentProductCategoryID, 3)) ~> filter3",
				"source1 filter(isNull(ParentProductCategoryID)) ~> filter4",
				"filter1 sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     partitionFileNames:['file1.csv'],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     partitionBy('hash', 1)) ~> sink1",
				"filter2 sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     partitionFileNames:['file2.csv'],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     partitionBy('hash', 1)) ~> sink2",
				"filter3 sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     partitionFileNames:['file3.csv'],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     partitionBy('hash', 1)) ~> sink3",
				"filter4 sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     partitionFileNames:['file4.csv'],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     partitionBy('hash', 1)) ~> sink4"
			]
		}
	}
}